{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YoloV5 Custom Training.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1aZsv8WJCABxBkKiBw6Na0m3NRxXExb7m","authorship_tag":"ABX9TyPcuZJlTJZyiF8z1gMsLvID"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["<img src =\"https://github.com/ultralytics/yolov5/releases/download/v1.0/splash.jpg\"> </img>"],"metadata":{"id":"KwZ7RUvBAUtb"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jBdDw7LhpfU","executionInfo":{"status":"ok","timestamp":1655658594316,"user_tz":-360,"elapsed":6,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"cfce16a7-06f6-438e-9035-a28ba63a991e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Tensorflow Developer/YoloV5/Android\n"]}],"source":["cd /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android"]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"I_Sl7xXVilW0","executionInfo":{"status":"ok","timestamp":1655658591890,"user_tz":-360,"elapsed":1016,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"b62ce4cf-eb92-4549-8989-8ac184533877"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YSjpJAdaimNA","executionInfo":{"status":"ok","timestamp":1655635094458,"user_tz":-360,"elapsed":4910,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"27e4561d-ac92-452a-b217-9cd2ccd9e839"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 12262, done.\u001b[K\n","remote: Counting objects: 100% (12/12), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 12262 (delta 2), reused 6 (delta 1), pack-reused 12250\u001b[K\n","Receiving objects: 100% (12262/12262), 11.96 MiB | 8.62 MiB/s, done.\n","Resolving deltas: 100% (8488/8488), done.\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHLe1nMgipMH","executionInfo":{"status":"ok","timestamp":1655658386459,"user_tz":-360,"elapsed":12,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"23a9f0de-fd36-4b65-c2b2-6b4f34a6652e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":[" \u001b[0m\u001b[01;34mandroid_figurine\u001b[0m/   \u001b[01;34myolov5\u001b[0m/  'YoloV5 Custom Training.ipynb'\n"]}]},{"cell_type":"code","source":["cd yolov5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KinlzT89irwR","executionInfo":{"status":"ok","timestamp":1655658601304,"user_tz":-360,"elapsed":1533,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"53b52820-d24e-4acb-ac32-c46ee21b42a1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/yolov5\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQJP7swNit8I","executionInfo":{"status":"ok","timestamp":1655658606700,"user_tz":-360,"elapsed":2526,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"b58abafb-ff13-4278-c024-27a7e43799c0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.1.2.30)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.23.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.4.1)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.11.0+cu113)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.12.0+cu113)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.64.0)\n","Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (3.17.3)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (2.8.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (1.3.5)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (0.11.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 35)) (5.5.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 36)) (5.4.8)\n","Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 37)) (0.1.0.post2206102148)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.24.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.1.1)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->-r requirements.txt (line 15)) (1.15.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.3.7)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.46.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.37.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 22)) (2022.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (4.4.2)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (1.0.18)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (0.8.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (5.1.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (2.6.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->-r requirements.txt (line 35)) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 35)) (0.7.0)\n"]}]},{"cell_type":"code","source":["import torch\n","import yaml\n","from IPython.display import Image, clear_output\n","from utils.plots import plot_results"],"metadata":{"id":"a9_Bi_O4iwZX","executionInfo":{"status":"ok","timestamp":1655658616751,"user_tz":-360,"elapsed":1347,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#Check GPU Availiblity\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0xr6YK4i57Q","executionInfo":{"status":"ok","timestamp":1655658618201,"user_tz":-360,"elapsed":16,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"d4453b7b-b3b5-4315-8c01-b715fbdec498"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Setup complete. Using torch 1.11.0+cu113 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S9i5tj22jdcN","executionInfo":{"status":"ok","timestamp":1655658417195,"user_tz":-360,"elapsed":21,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"b5a484ca-093f-46ba-e68c-8ff2008586db"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":[" CONTRIBUTING.md  'IMG_0509 (1).jpg'   requirements.txt   \u001b[0m\u001b[01;34mutils\u001b[0m/\n"," \u001b[01;34mdata\u001b[0m/             LICENSE             \u001b[01;34mruns\u001b[0m/              val.py\n"," detect.py         \u001b[01;34mmodels\u001b[0m/             setup.cfg          yolov5m.pt\n"," export.py         \u001b[01;34m__pycache__\u001b[0m/        train.py\n"," hubconf.py        README.md           tutorial.ipynb\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ykKzz9XzjeBM","executionInfo":{"status":"ok","timestamp":1655636479136,"user_tz":-360,"elapsed":1380,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"c429fb18-1beb-49f5-9d0b-d8cada436a90"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/yolov5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["!wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5m.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ELOZtTeMoHZ-","executionInfo":{"status":"ok","timestamp":1655636622652,"user_tz":-360,"elapsed":1883,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"e6cac74c-4ad2-46e7-d84e-f5ae62827fff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-06-19 11:03:41--  https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5m.pt\n","Resolving github.com (github.com)... 140.82.121.3\n","Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/77bb6f54-77c5-4161-b921-b225b7bb730e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220619%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220619T110341Z&X-Amz-Expires=300&X-Amz-Signature=7d047b59238a0b9aa12c7280a80358804cb88c8f45e6ad8745af444d424fd611&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream [following]\n","--2022-06-19 11:03:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/77bb6f54-77c5-4161-b921-b225b7bb730e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220619%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220619T110341Z&X-Amz-Expires=300&X-Amz-Signature=7d047b59238a0b9aa12c7280a80358804cb88c8f45e6ad8745af444d424fd611&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5m.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 42806829 (41M) [application/octet-stream]\n","Saving to: ‘yolov5m.pt’\n","\n","yolov5m.pt          100%[===================>]  40.82M  35.5MB/s    in 1.2s    \n","\n","2022-06-19 11:03:43 (35.5 MB/s) - ‘yolov5m.pt’ saved [42806829/42806829]\n","\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ZQMYXYlfrc-O","executionInfo":{"status":"ok","timestamp":1655637402683,"user_tz":-360,"elapsed":517,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"295459d4-337a-497c-9f65-e36d18acd366"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/yolov5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["<img src=\"https://user-images.githubusercontent.com/26833433/155040763-93c22a27-347c-4e3c-847a-8094621d3f4e.png\"> </img>"],"metadata":{"id":"7_c4Jd2uAlP3"}},{"cell_type":"code","source":["!python train.py --img 640 --batch 8 --epochs 35 --data coco128.yaml --weights yolov5m.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uNoUqCbZoe-V","executionInfo":{"status":"ok","timestamp":1655638428815,"user_tz":-360,"elapsed":295327,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"f9fce41f-44a5-47b1-cf6a-448b80db547b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=35, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","fatal: cannot change to '/content/drive/MyDrive/Tensorflow': No such file or directory\n","YOLOv5 🚀 2022-6-19 Python-3.7.13 torch-1.11.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=2\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n","  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n","  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n","  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n","  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n","  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n","  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n","  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n","  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n","  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n"," 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n"," 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n"," 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n"," 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 24      [17, 20, 23]  1     28287  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n","Model summary: 369 layers, 20875359 parameters, 20875359 gradients\n","\n","Transferred 475/481 items from yolov5m.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 79 weight (no decay), 82 weight, 82 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/labels' images and labels...62 found, 0 missing, 0 empty, 0 corrupt: 100% 62/62 [00:39<00:00,  1.59it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/test/labels' images and labels...10 found, 0 missing, 0 empty, 0 corrupt: 100% 10/10 [00:12<00:00,  1.26s/it]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/test/labels.cache\n","Plotting labels to runs/train/exp3/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.01 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp3\u001b[0m\n","Starting training for 35 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      0/34     3.19G    0.1058   0.02992   0.02883        19       640: 100% 8/8 [00:08<00:00,  1.10s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.05it/s]\n","                 all         10         17    0.00466      0.819    0.00816    0.00213\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      1/34     3.32G   0.09029   0.03168   0.02841        14       640: 100% 8/8 [00:02<00:00,  2.75it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.40it/s]\n","                 all         10         17    0.00534      0.944     0.0458     0.0111\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      2/34     3.32G   0.07052   0.03205    0.0255         8       640: 100% 8/8 [00:02<00:00,  3.02it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.71it/s]\n","                 all         10         17      0.284      0.278      0.381      0.124\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      3/34     3.32G   0.06769   0.03164    0.0242        19       640: 100% 8/8 [00:02<00:00,  2.83it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.27it/s]\n","                 all         10         17      0.189      0.482      0.294      0.102\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      4/34     3.32G   0.06655   0.02866   0.02298        14       640: 100% 8/8 [00:03<00:00,  2.18it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.15it/s]\n","                 all         10         17      0.282      0.514      0.429      0.184\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      5/34     3.32G   0.06586   0.02774   0.02245        18       640: 100% 8/8 [00:03<00:00,  2.27it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  1.91it/s]\n","                 all         10         17      0.188      0.514      0.302     0.0638\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      6/34     3.32G   0.07361   0.02368   0.02461        13       640: 100% 8/8 [00:03<00:00,  2.22it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.63it/s]\n","                 all         10         17      0.407      0.427      0.545      0.155\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      7/34     3.32G   0.06661   0.02443   0.02239        12       640: 100% 8/8 [00:03<00:00,  2.56it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  4.58it/s]\n","                 all         10         17      0.479      0.718      0.611      0.145\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      8/34     3.32G   0.05558   0.02153   0.01669        15       640: 100% 8/8 [00:03<00:00,  2.38it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.54it/s]\n","                 all         10         17      0.654      0.604      0.611      0.244\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      9/34     3.32G   0.07631   0.01989   0.01537         9       640: 100% 8/8 [00:02<00:00,  2.96it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.59it/s]\n","                 all         10         17      0.729      0.639      0.557      0.262\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     10/34     3.32G   0.06802   0.02341   0.01416        16       640: 100% 8/8 [00:02<00:00,  3.00it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.68it/s]\n","                 all         10         17      0.722      0.854      0.704      0.334\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     11/34     3.32G   0.06356   0.01951   0.01316        16       640: 100% 8/8 [00:02<00:00,  3.00it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.62it/s]\n","                 all         10         17      0.726      0.975      0.763      0.382\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     12/34     3.32G     0.072   0.02043   0.01207        17       640: 100% 8/8 [00:02<00:00,  2.92it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.39it/s]\n","                 all         10         17      0.676          1      0.697      0.332\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     13/34     3.32G   0.07201   0.01942   0.01313        18       640: 100% 8/8 [00:03<00:00,  2.53it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  4.09it/s]\n","                 all         10         17      0.338      0.556      0.356      0.168\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     14/34     3.32G   0.06707   0.01944   0.01154        18       640: 100% 8/8 [00:03<00:00,  2.32it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.48it/s]\n","                 all         10         17      0.438      0.819      0.586      0.269\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     15/34     3.32G   0.06491   0.01838  0.009987        22       640: 100% 8/8 [00:03<00:00,  2.54it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  4.43it/s]\n","                 all         10         17      0.715      0.998      0.981      0.546\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     16/34     3.32G    0.0642    0.0179  0.007128        16       640: 100% 8/8 [00:02<00:00,  2.85it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  4.22it/s]\n","                 all         10         17      0.815       0.97      0.988      0.497\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     17/34     3.32G   0.05355   0.01767  0.009251        12       640: 100% 8/8 [00:03<00:00,  2.18it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.62it/s]\n","                 all         10         17      0.754      0.939      0.975      0.568\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     18/34     3.32G   0.05899    0.0177  0.008353        17       640: 100% 8/8 [00:02<00:00,  3.04it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  4.21it/s]\n","                 all         10         17      0.722      0.944      0.964      0.688\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     19/34     3.32G   0.05636   0.01655  0.008841        13       640: 100% 8/8 [00:02<00:00,  2.79it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.78it/s]\n","                 all         10         17      0.907      0.971      0.995      0.609\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     20/34     3.32G   0.05254   0.01761  0.007042        15       640: 100% 8/8 [00:03<00:00,  2.53it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.27it/s]\n","                 all         10         17       0.93      0.944       0.99      0.744\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     21/34     3.32G    0.0522    0.0171  0.006203        13       640: 100% 8/8 [00:02<00:00,  3.12it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.82it/s]\n","                 all         10         17      0.926      0.974      0.995      0.723\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     22/34     3.32G   0.05208   0.01425  0.005334        15       640: 100% 8/8 [00:03<00:00,  2.54it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.39it/s]\n","                 all         10         17      0.936      0.975      0.995      0.617\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     23/34     3.32G   0.05415   0.01703  0.005792        12       640: 100% 8/8 [00:03<00:00,  2.37it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.65it/s]\n","                 all         10         17      0.815      0.967      0.974      0.646\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     24/34     3.32G   0.05175   0.01499  0.005283        12       640: 100% 8/8 [00:02<00:00,  2.70it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  2.84it/s]\n","                 all         10         17      0.871      0.989      0.995      0.697\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     25/34     3.32G   0.04897   0.01472  0.004519        19       640: 100% 8/8 [00:03<00:00,  2.59it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  4.26it/s]\n","                 all         10         17      0.957          1      0.995      0.764\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     26/34     3.32G   0.05097   0.01352  0.004358        16       640: 100% 8/8 [00:02<00:00,  3.09it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.91it/s]\n","                 all         10         17      0.954          1      0.995       0.69\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     27/34     3.32G   0.05372   0.01382  0.003795        13       640: 100% 8/8 [00:03<00:00,  2.28it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.29it/s]\n","                 all         10         17      0.876      0.978      0.995      0.699\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     28/34     3.32G   0.04711   0.01595  0.003628        13       640: 100% 8/8 [00:03<00:00,  2.53it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  4.17it/s]\n","                 all         10         17      0.935          1      0.995      0.741\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     29/34     3.32G   0.04609   0.01322  0.002521        20       640: 100% 8/8 [00:03<00:00,  2.51it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.32it/s]\n","                 all         10         17      0.948          1      0.995      0.766\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     30/34     3.32G   0.04375   0.01326  0.002563        14       640: 100% 8/8 [00:02<00:00,  3.10it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  5.45it/s]\n","                 all         10         17      0.967          1      0.995      0.771\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     31/34     3.32G   0.04658   0.01494  0.003547        15       640: 100% 8/8 [00:02<00:00,  2.94it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  5.91it/s]\n","                 all         10         17      0.969          1      0.995      0.805\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     32/34     3.32G   0.03949   0.01336  0.003644        18       640: 100% 8/8 [00:02<00:00,  2.71it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.69it/s]\n","                 all         10         17       0.97          1      0.995      0.758\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     33/34     3.32G   0.04737   0.01331  0.002936        16       640: 100% 8/8 [00:03<00:00,  2.35it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.72it/s]\n","                 all         10         17      0.973          1      0.995      0.775\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     34/34     3.32G   0.03875   0.01267  0.003032        10       640: 100% 8/8 [00:03<00:00,  2.49it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  5.92it/s]\n","                 all         10         17      0.977          1      0.995      0.807\n","\n","35 epochs completed in 0.060 hours.\n","Optimizer stripped from runs/train/exp3/weights/last.pt, 42.2MB\n","Optimizer stripped from runs/train/exp3/weights/best.pt, 42.2MB\n","\n","Validating runs/train/exp3/weights/best.pt...\n","Fusing layers... \n","Model summary: 290 layers, 20856975 parameters, 0 gradients\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:00<00:00,  3.40it/s]\n","                 all         10         17      0.977          1      0.995      0.807\n","             android         10          8      0.968          1      0.995      0.815\n","         pig_android         10          9      0.987          1      0.995      0.798\n","Results saved to \u001b[1mruns/train/exp3\u001b[0m\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"aTH_n2xuw-Zf","executionInfo":{"status":"ok","timestamp":1655639098970,"user_tz":-360,"elapsed":519,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"8470bc59-ee16-4740-d60b-9caae97083b9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/yolov5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["!python val.py --weights runs/train/exp3/weights/best.pt --data coco128.yaml --img 640"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_a-0smopv4Kp","executionInfo":{"status":"ok","timestamp":1655639286534,"user_tz":-360,"elapsed":18168,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"df4ffd98-2de9-409c-8975-0ea824c0cbc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/yolov5/data/coco128.yaml, weights=['runs/train/exp3/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n","fatal: cannot change to '/content/drive/MyDrive/Tensorflow': No such file or directory\n","YOLOv5 🚀 2022-6-19 Python-3.7.13 torch-1.11.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","Model summary: 290 layers, 20856975 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/test/labels.cache' images and labels... 10 found, 0 missing, 0 empty, 0 corrupt: 100% 10/10 [00:00<?, ?it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:03<00:00,  3.65s/it]\n","                 all         10         17      0.977          1      0.995      0.807\n","             android         10          8      0.968          1      0.995      0.815\n","         pig_android         10          9      0.987          1      0.995      0.798\n","Speed: 0.2ms pre-process, 18.2ms inference, 2.0ms NMS per image at shape (32, 3, 640, 640)\n","Results saved to \u001b[1mruns/val/exp5\u001b[0m\n"]}]},{"cell_type":"code","source":["!python detect.py --weights runs/train/exp3/weights/best.pt --img 640 --conf 0.5 --source ../android_figurine/train/images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBK0GvQfyx0O","executionInfo":{"status":"ok","timestamp":1655639876495,"user_tz":-360,"elapsed":9700,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"01a4db70-ca27-4c24-eee4-cc0167ca7521"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp3/weights/best.pt'], source=../android_figurine/train/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n","fatal: cannot change to '/content/drive/MyDrive/Tensorflow': No such file or directory\n","YOLOv5 🚀 2022-6-19 Python-3.7.13 torch-1.11.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","Model summary: 290 layers, 20856975 parameters, 0 gradients\n","image 1/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0509.jpg: 480x640 1 android, 1 pig_android, Done. (0.024s)\n","image 2/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0510.jpg: 480x640 1 android, Done. (0.023s)\n","image 3/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0511.jpg: 480x640 1 android, Done. (0.023s)\n","image 4/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0512.jpg: 480x640 1 android, 1 pig_android, Done. (0.020s)\n","image 5/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0513.jpg: 480x640 1 android, Done. (0.019s)\n","image 6/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0514.jpg: 480x640 1 android, Done. (0.019s)\n","image 7/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0515.jpg: 480x640 1 android, Done. (0.019s)\n","image 8/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0516.jpg: 480x640 1 android, Done. (0.019s)\n","image 9/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0517.jpg: 480x640 1 android, Done. (0.016s)\n","image 10/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0518.jpg: 480x640 1 android, Done. (0.019s)\n","image 11/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0519.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 12/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0520.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 13/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0521.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 14/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0522.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 15/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0523.jpg: 480x640 1 android, 1 pig_android, Done. (0.016s)\n","image 16/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0524.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 17/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0525.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 18/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0526.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 19/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0527.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 20/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0528.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 21/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0529.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 22/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0530.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 23/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0531.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 24/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0532.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 25/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0533.jpg: 480x640 1 pig_android, Done. (0.023s)\n","image 26/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0534.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 27/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0535.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 28/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0536.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 29/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0537.jpg: 480x640 1 android, 1 pig_android, Done. (0.016s)\n","image 30/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0538.jpg: 480x640 1 android, Done. (0.016s)\n","image 31/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0539.jpg: 480x640 1 android, Done. (0.016s)\n","image 32/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0540.jpg: 480x640 1 android, Done. (0.016s)\n","image 33/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0541.jpg: 480x640 1 android, Done. (0.017s)\n","image 34/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0542.jpg: 480x640 1 android, Done. (0.016s)\n","image 35/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0543.jpg: 480x640 1 android, Done. (0.016s)\n","image 36/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0544.jpg: 480x640 1 android, Done. (0.016s)\n","image 37/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0545.jpg: 480x640 1 android, Done. (0.016s)\n","image 38/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0546.jpg: 480x640 1 android, 1 pig_android, Done. (0.016s)\n","image 39/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0547.jpg: 480x640 1 android, 1 pig_android, Done. (0.016s)\n","image 40/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0548.jpg: 480x640 1 android, 1 pig_android, Done. (0.016s)\n","image 41/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0549.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 42/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0550.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 43/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0551.jpg: 480x640 1 pig_android, Done. (0.017s)\n","image 44/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0552.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 45/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0553.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 46/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0554.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 47/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0555.jpg: 480x640 1 android, Done. (0.016s)\n","image 48/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0556.jpg: 480x640 1 android, 1 pig_android, Done. (0.017s)\n","image 49/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0557.jpg: 480x640 1 android, Done. (0.016s)\n","image 50/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0558.jpg: 480x640 1 android, Done. (0.016s)\n","image 51/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0559.jpg: 480x640 1 android, Done. (0.016s)\n","image 52/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0560.jpg: 480x640 1 android, 1 pig_android, Done. (0.016s)\n","image 53/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0561.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 54/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0562.jpg: 480x640 1 pig_android, Done. (0.016s)\n","image 55/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0563.jpg: 480x640 1 android, 1 pig_android, Done. (0.017s)\n","image 56/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0564.jpg: 480x640 1 android, 1 pig_android, Done. (0.016s)\n","image 57/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0565.jpg: 480x640 1 android, Done. (0.016s)\n","image 58/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0566.jpg: 480x640 1 android, Done. (0.016s)\n","image 59/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0567.jpg: 480x640 1 android, 1 pig_android, Done. (0.016s)\n","image 60/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0568.jpg: 480x640 1 android, Done. (0.016s)\n","image 61/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0569.jpg: 480x640 1 android, Done. (0.016s)\n","image 62/62 /content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/android_figurine/train/images/IMG_0571.jpg: 480x640 1 android, Done. (0.015s)\n","Speed: 0.4ms pre-process, 16.8ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"4gx-2bU97MP1","executionInfo":{"status":"ok","timestamp":1655658625680,"user_tz":-360,"elapsed":831,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"3839d2c9-3c50-4e4a-a1f5-fe03a1892854"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Tensorflow Developer/YoloV5/Android/yolov5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["best_weight_path=\"/runs/train/exp3/weights/best.pt\""],"metadata":{"id":"jR1Hd_Ya7OD0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torch.hub.load('ultralytics/yolov5', 'custom', path='runs/train/exp3/weights/best.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w738_P_g7Vix","executionInfo":{"status":"ok","timestamp":1655658634391,"user_tz":-360,"elapsed":5069,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"e6b661e2-a313-49ae-dbf8-01d6129b8955"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n","YOLOv5 🚀 2022-6-19 Python-3.7.13 torch-1.11.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","Model summary: 290 layers, 20856975 parameters, 0 gradients\n","Adding AutoShape... \n"]}]},{"cell_type":"code","source":["\n","# Images\n","img = 'IMG_0509 (1).jpg'  # or file, Path, PIL, OpenCV, numpy, list\n","\n","# Inference\n","results = model(img)\n","\n"],"metadata":{"id":"V3vmpzxd70u6","executionInfo":{"status":"ok","timestamp":1655658668215,"user_tz":-360,"elapsed":872,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Results\n","results.print()  # or .show(), .save(), .crop(), .pandas(), etc."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3IuakqI8lHb","executionInfo":{"status":"ok","timestamp":1655658674559,"user_tz":-360,"elapsed":637,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"3c0d2361-900e-4f40-ec22-51e78019feb0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["image 1/1: 600x800 1 android, 1 pig_android\n","Speed: 670.1ms pre-process, 266.6ms inference, 23.6ms NMS per image at shape (1, 3, 480, 640)\n"]}]},{"cell_type":"code","source":["results.pandas().xyxy[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"QM6raI5t8toy","executionInfo":{"status":"ok","timestamp":1655658704391,"user_tz":-360,"elapsed":1050,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"f6f22ef8-4f41-4227-e1e4-0683a8ad53a1"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         xmin        ymin        xmax        ymax  confidence  class  \\\n","0  525.512146   73.685883  727.088379  328.193176    0.868957      1   \n","1    0.000000  116.960861  296.018372  408.904236    0.822167      0   \n","\n","          name  \n","0  pig_android  \n","1      android  "],"text/html":["\n","  <div id=\"df-d687e091-741e-4788-adb0-eb9802ef2b16\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","      <th>confidence</th>\n","      <th>class</th>\n","      <th>name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>525.512146</td>\n","      <td>73.685883</td>\n","      <td>727.088379</td>\n","      <td>328.193176</td>\n","      <td>0.868957</td>\n","      <td>1</td>\n","      <td>pig_android</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>116.960861</td>\n","      <td>296.018372</td>\n","      <td>408.904236</td>\n","      <td>0.822167</td>\n","      <td>0</td>\n","      <td>android</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d687e091-741e-4788-adb0-eb9802ef2b16')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d687e091-741e-4788-adb0-eb9802ef2b16 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d687e091-741e-4788-adb0-eb9802ef2b16');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["xmin = results.pandas().xyxy[0][\"xmin\"]\n","ymin = results.pandas().xyxy[0][\"ymin\"]\n","xmax = results.pandas().xyxy[0][\"xmax\"]\n","ymax = results.pandas().xyxy[0][\"ymax\"]\n","name = results.pandas().xyxy[0][\"name\"]"],"metadata":{"id":"tOXkgRZe8xz3","executionInfo":{"status":"ok","timestamp":1655658834035,"user_tz":-360,"elapsed":598,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["print(xmin)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txRbg_zM9Opv","executionInfo":{"status":"ok","timestamp":1655658843707,"user_tz":-360,"elapsed":12,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"6b365481-f7ce-4ec8-900e-390b8577f656"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["0    525.512146\n","1      0.000000\n","Name: xmin, dtype: float64\n"]}]},{"cell_type":"code","source":["print(xmax)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33rkbjbl9QGd","executionInfo":{"status":"ok","timestamp":1655658852053,"user_tz":-360,"elapsed":15,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"543a0e52-446b-48a4-f515-ba12fda6ed4d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["0    727.088379\n","1    296.018372\n","Name: xmax, dtype: float64\n"]}]},{"cell_type":"code","source":["print(ymin)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6PVGCyc09SR7","executionInfo":{"status":"ok","timestamp":1655658856778,"user_tz":-360,"elapsed":14,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"2f2ddb20-7505-499d-d16a-31831f2f442a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["0     73.685883\n","1    116.960861\n","Name: ymin, dtype: float64\n"]}]},{"cell_type":"code","source":["print(ymax)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZzeRJ9_b9T1u","executionInfo":{"status":"ok","timestamp":1655658864599,"user_tz":-360,"elapsed":1030,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"e53aee41-d972-4311-94b8-ce56f32dd160"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["0    328.193176\n","1    408.904236\n","Name: ymax, dtype: float64\n"]}]},{"cell_type":"code","source":["print(name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2EZdwbO9VKp","executionInfo":{"status":"ok","timestamp":1655658869383,"user_tz":-360,"elapsed":1295,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"9f2a01bd-d1f2-45fa-d820-68abe2d4163d"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["0    pig_android\n","1        android\n","Name: name, dtype: object\n"]}]},{"cell_type":"code","source":["xmin.tolist()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w5Altm-D9WMx","executionInfo":{"status":"ok","timestamp":1655658965511,"user_tz":-360,"elapsed":609,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"6fb3728f-2d2a-4c79-f7f8-8e326dbde0d8"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[525.5121459960938, 0.0]"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["name.tolist()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rS8slYuu9vev","executionInfo":{"status":"ok","timestamp":1655658974963,"user_tz":-360,"elapsed":16,"user":{"displayName":"S.M.ABRAR MUSTAKIM TAKI","userId":"04264818990090801992"}},"outputId":"9e364b48-1434-4e1a-c780-69a70277c182"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['pig_android', 'android']"]},"metadata":{},"execution_count":22}]}]}